{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wNJ_rSNWgPs2"
      },
      "source": [
        "### Single-label Album Cover Classification of the MUMU Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lz1dZ_pgPtI"
      },
      "source": [
        "In this project we attempt to create an algorithm that classifies album cover art by their musical genres. We do this by implementing different convolutional neural networks. Our motivation for this project is both of our liking towards music and our appreciation for album cover art! We both thought it would be an interesting attempt to see if we can create a network that can accurately classify the genre as we believe that the cover art sets the tone for an album and that there are many giving signs for this. Essentially, the differences in styles can be obvious to human observers and we wanted to test if machines can detect them as well. A total of 18,584 album covers and 18,584 labels from the MUMU dataset were acquired , with 80% allocated to training, 10% to testing and 10% to development. The album covers were expected to be classified as one of the following labels: 0 - Alternative Rock, 1 - Christian, 2 - Classical, 3 - Country, 4 - Dance & Electronic, 5 - Folk, 6 - Jazz, 7 - Latin Music, 8 - Metal, 9 - R&B, 10 - Rap & Hip-Hop, 11 Reggae. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjV3dpE3gPtK"
      },
      "source": [
        " The MUMU dataset was first downloaded and sorted into directories using the code found here: https://github.com/koenig125/album-artwork-classification/blob/single-label-classifier/build_dataset.py\n",
        "\n",
        " Next, we processed the train, test, and dev data into usable numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z04k85UZgPtL"
      },
      "outputs": [],
      "source": [
        "data_dir = '..\\\\album-artwork-classification\\\\data\\\\300x300_MUMU'  # local path\n",
        "train_dir = data_dir + '\\\\train\\\\images'\n",
        "test_dir = data_dir + '\\\\test\\\\images'\n",
        "dev_dir = data_dir + '\\\\dev\\\\images'\n",
        "train_genres = data_dir + '\\\\train\\\\genres\\\\y_train.npy'\n",
        "test_genres = data_dir + '\\\\test\\\\genres\\\\y_test.npy'\n",
        "dev_genres = data_dir + '\\\\dev\\\\genres\\\\y_dev.npy'\n",
        "\n",
        "# filenames of the image files\n",
        "train_filenames = sorted(\n",
        "    [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.endswith('.jpg')],\n",
        "    key=os.path.getctime)\n",
        "test_filenames = sorted(\n",
        "    [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith('.jpg')],\n",
        "    key=os.path.getctime)\n",
        "dev_filenames = sorted(\n",
        "    [os.path.join(dev_dir, f) for f in os.listdir(dev_dir) if f.endswith('.jpg')],\n",
        "    key=os.path.getctime)\n",
        "\n",
        "# binary vectors representing all genres\n",
        "y_train = np.load(train_genres)\n",
        "y_test = np.load(test_genres)\n",
        "y_dev = np.load(dev_genres)\n",
        "\n",
        "photos_dev = []\n",
        "photos_train = []\n",
        "photos_test = []\n",
        "for file in dev_filenames:\n",
        "    photo = tf.keras.preprocessing.image.load_img(file, target_size=(128, 128))\n",
        "    #convert to numpy array\n",
        "    photo = tf.keras.preprocessing.image.img_to_array(photo)\n",
        "    #store\n",
        "    photos_dev.append(photo/255)\n",
        "x_dev = np.asarray(photos_dev)\n",
        "print('done dev')\n",
        "\n",
        "for file in train_filenames:\n",
        "    photo = tf.keras.preprocessing.image.load_img(file, target_size=(128, 128))\n",
        "    photo = tf.keras.preprocessing.image.img_to_array(photo)\n",
        "    photos_train.append(photo/255)\n",
        "x_train = np.asarray(photos_train)\n",
        "print('done train')\n",
        "\n",
        "for file in test_filenames:\n",
        "    photo = tf.keras.preprocessing.image.load_img(file, target_size=(128, 128))\n",
        "    photo = tf.keras.preprocessing.image.img_to_array(photo)\n",
        "    photos_test.append(photo/255)\n",
        "x_test = np.asarray(photos_test)\n",
        "print('done test')\n",
        "\n",
        "print(\"x_dev shape:\", x_dev.shape)\n",
        "print(\"x_train shape:\",x_train.shape)\n",
        "print(\"x_test shape:\",x_test.shape)\n",
        "\n",
        "print(\"y_dev shape:\", y_dev.shape)\n",
        "print(\"y_train shape:\",y_train.shape)\n",
        "print(\"y_test shape:\",y_test.shape)\n",
        "\n",
        "plt.imshow(x_dev[0])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "print(\"y_dev:\",y_dev[0])\n",
        "\n",
        "plt.imshow(x_train[0])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "print(\"y_train:\",y_train[0])\n",
        "\n",
        "plt.imshow(x_test[0])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "print(\"y_test:\",y_test[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAvI2jTItAXs"
      },
      "source": [
        "The genre labels are integers from 0 to 11, corresponding to the following genres:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDkjyFPMsvsq",
        "outputId": "8e584d5f-e16d-48d0-c099-6f219d1131da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Genre: 0 Alternative Rock\n",
            "Genre: 1 Christian\n",
            "Genre: 2 Classical\n",
            "Genre: 3 Country\n",
            "Genre: 4 Dance & Electronic\n",
            "Genre: 5 Folk\n",
            "Genre: 6 Jazz\n",
            "Genre: 7 Latin Music\n",
            "Genre: 8 Metal\n",
            "Genre: 9 R&B\n",
            "Genre: 10 Rap & Hip-Hop\n",
            "Genre: 11 Reggae\n"
          ]
        }
      ],
      "source": [
        "genre_list = ['Metal', 'Alternative Rock', 'Dance & Electronic', 'Rap & Hip-Hop', 'R&B',\n",
        "              'Jazz', 'Folk', 'Country', 'Latin Music', 'Reggae', 'Classical', 'Christian']\n",
        "genre_list.sort()\n",
        "for i in range(len(genre_list)):\n",
        "    print(\"Genre:\", i, genre_list[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbS_nfFcgPtT"
      },
      "source": [
        "## 1. Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZFnKe7pgPtV"
      },
      "source": [
        "We started classfication with the base model given to us from assignment 2.\n",
        "We ensured to use a softmax output, sparse categorical cross entropy layer because we have 12 labels and the adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8e7pakHgPtX"
      },
      "outputs": [],
      "source": [
        "def my_loss(y_true, y_predict):\n",
        "    return (y_true-y_predict)**2\n",
        "\n",
        "a = []\n",
        "b = []\n",
        "c = []\n",
        "d = []\n",
        "\n",
        "\n",
        "weight_decay = 1e-4\n",
        "for _ in range(5):    \n",
        "        model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "          tf.keras.layers.Flatten(),    \n",
        "          tf.keras.layers.Dense(64, activation='relu'),\n",
        "          tf.keras.layers.Dense(12, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                     )\n",
        "        \n",
        "        model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))        \n",
        "        \n",
        "        a.append(model.history.history['accuracy'])\n",
        "        b.append(model.history.history['loss'])\n",
        "        c.append(model.history.history['val_loss'])\n",
        "        d.append(model.history.history['val_accuracy'])\n",
        "        \n",
        "print(\"a:\",a)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model.history.history['accuracy'], c='k')\n",
        "plt.ylabel('training accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.twinx()\n",
        "plt.plot(model.history.history['loss'], c='b')\n",
        "plt.ylabel('training loss (error)')\n",
        "plt.title('training')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.history.history['val_accuracy'], c='k')\n",
        "plt.ylabel('testing accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.twinx()\n",
        "plt.plot(model.history.history['val_loss'], c='b')\n",
        "plt.ylabel('testing loss (error)')\n",
        "plt.title('testing')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#PLOTTING 10 MODELS\n",
        "\n",
        "for i in range(5):\n",
        "    plt.plot(a[i], label = str(i+1))\n",
        "plt.ylabel('training accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('Training for 10 runs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    plt.plot(d[i], label = str(i+1))\n",
        "plt.ylabel('testing accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('Testing for 10 runs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Part 1 question 2\n",
        "\n",
        "for i in range(5):\n",
        "    plt.plot(b[i], label = str(i+1))\n",
        "plt.ylabel('training error')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('Training for 10 runs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    plt.plot(c[i], label = str(i+1))\n",
        "plt.ylabel('testing error')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('Testing for 10 runs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssIXXFPhgPta"
      },
      "source": [
        "Plot results for Model 1:\n",
        "<img src='https://drive.google.com/uc?id=1b9YhZ_6-EnkH0BNpgcwCUJQd1gLWqg-d'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1NXC2Zrk2Ydku-sa4dAGPH2Qz8SgqdMEz'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1GN2EUJCb92AYcTd7ZD4YGbCc1lFsQTES'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1r17ACNar-QCKweaC0pS03rooZfGnN5i3'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1rTlf25EQwjTaFopLED6lyquy6Zydvn2G'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0t4hK4GgPtc"
      },
      "source": [
        "Overfitting is when the testing error starts increasing while the training error continues to decrease. We assumed that the model was quickly learning how to model the training data and not the testing data. Methods will be introduced to address the overfitting occuring in the architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLMJxefFgPtd"
      },
      "source": [
        "## 2. Model with Activity regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TAy7dThgPtd"
      },
      "source": [
        "Activity regularization is an approach to encourage a neural network to learn sparse features. The regularizer function applied to the output of the layer (its \"activation\") and is mostly used to regularize hidden units. These update the general cost function by adding another term known as the regularization term. As a result of the additional regularization term, the values of weight matrices decrease because it assumes that a neural network with smaller weight matrices leads to simpler models. Therefore, it also reduces overfitting significantly. \n",
        "\n",
        "Additionally we attempted to use 90x90 pixelated images and have the same dimesions for the first input layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnBxXg8LgPte"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):    \n",
        "        model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(90, (3, 3), activation='relu', input_shape=(90, 90, 3)),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu', activity_regularizer= tf.keras.regularizers.l1(0.001)),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu', activity_regularizer= tf.keras.regularizers.l1(0.001)),\n",
        "          tf.keras.layers.Flatten(),    \n",
        "          tf.keras.layers.Dense(64, activation='relu'),\n",
        "          tf.keras.layers.Dense(12, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                     )\n",
        "        \n",
        "        model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))        \n",
        "        \n",
        "        a.append(model.history.history['accuracy'])\n",
        "        b.append(model.history.history['loss'])\n",
        "        c.append(model.history.history['val_loss'])\n",
        "        d.append(model.history.history['val_accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_bPMAQSgPtg"
      },
      "source": [
        "actual output from network: [0.24964698 0.02952243 0.01603668 0.06710279 0.11900116 0.05433126\n",
        " 0.14699052 0.07987288 0.10439866 0.07019878 0.0367722  0.02612562]\n",
        "category (the largest output): 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TnsN24AgPth"
      },
      "source": [
        "Plot results for Model 2:\n",
        "<img src='https://drive.google.com/uc?id=1li8YyC3c88SJb4uP23DBDwsMqxT7LiZI'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1uUEc3lh6H_B91coAitxXvWOEVbv_LwCt'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAj9g-9AgPtj"
      },
      "source": [
        "## 3.  Convolutional Model with Higher Learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "601pJEQ0zy8K"
      },
      "source": [
        "A higher learning rate of 0.01, compared to the other models which used 0.001, was tried to see the effects on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7eM5MnHgPtj"
      },
      "outputs": [],
      "source": [
        "# Trying a higher learning rate\n",
        "fig, ax = plt.subplots(4, figsize=(12,44))\n",
        "for n in range(10):\n",
        "    print(f'run {n}')\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Flatten(),    \n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
        "    ax[0].plot(model.history.history['accuracy'])\n",
        "    ax[1].plot(model.history.history['val_accuracy'])\n",
        "    print('Validation accuracy: ', model.history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Basic Convolutional Model w/ LRate=0.01')\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('training accuracy')\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('testing accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQM_eJzCgPtk"
      },
      "source": [
        "**Plot results for Model 3:**\n",
        "\n",
        "Training Accuracy\n",
        "<img src='https://drive.google.com/uc?id=1odtm47GOVLq4Ege5x0BDqXcapV3olc2z'>\n",
        "\n",
        "Testing Accuracy\n",
        "<img src='https://drive.google.com/uc?id=1LZSWkjX4ZqFUlgy8ynFnNibu4KYmxb58'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLxU_ydj0C4Q"
      },
      "source": [
        "As seen in the plots above, every run produced the same result of ~25.7% accuracy, which did not increase or decrease through 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxfLRd0ggPtk"
      },
      "source": [
        "## 4.1 Convolutional Model with Dropout Layers 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnkB4ewIgPtl"
      },
      "source": [
        "Another way to address overfitting is adding dropout layers. Dropout is another regularization method where some number of layer outputs are randomly dropped out during training. This creates the effect of making the layer appear to be a layer with a different number of nodes and connectivity to the previous layer. Essentially, while training it is performed with a different view of the layer through each update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNSudsdrgPtl"
      },
      "outputs": [],
      "source": [
        "        model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Dropout(0.2),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Dropout(0.2),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "          tf.keras.layers.Flatten(),    \n",
        "          tf.keras.layers.Dense(64, activation='relu'),\n",
        "          tf.keras.layers.Dropout(0.2),\n",
        "          tf.keras.layers.Dense(12, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                     )\n",
        "        \n",
        "        model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))        \n",
        "        \n",
        "        a.append(model.history.history['accuracy'])\n",
        "        b.append(model.history.history['loss'])\n",
        "        c.append(model.history.history['val_loss'])\n",
        "        d.append(model.history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOsOLaCdgPtm"
      },
      "source": [
        "**Plot results for Model 4.1:**\n",
        "\n",
        "Training Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1eSz8m_DQSCGj45PiINS5m7zKA28lAMK8'>\n",
        "\n",
        "Testing Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1xesEIdydZQnIPsMBvj1brwOj__lttLFI'>\n",
        "\n",
        "Training Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1MNGnZI9tMLlqvqzFRK3EfO0USSousY7t'>\n",
        "\n",
        "Testing Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=111eDIKsMQGANy6SVNgKjl3i2FQcaMdNQ'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4E0lYO_1VRT"
      },
      "source": [
        "While the training accuracy continues to increase from ~25% to between 40-55% accuracy in 10 epochs, the testing accuracy actually begins to decrease after 4-6 epochs. This decrease indicates that there is still overfitting in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbMo9V3wgPto"
      },
      "source": [
        "## 4.2 Convolutional Model with Dropout Layers 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGwomURzgPto"
      },
      "source": [
        "We decided to run the same model as seen above except this time we created 128 neurons in the input layer and keep the neurons in the following layers to be the same size. We decided to implement this change as it is typically better practice to have the input neurons be the same dimensions as the pixels of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUYxzM7ZgPto"
      },
      "outputs": [],
      "source": [
        "# Change the input layer to 128 neurons\n",
        "\n",
        "fig, ax = plt.subplots(2, figsize=(12,24))\n",
        "for n in range(10):\n",
        "    print(f'run {n}')\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Flatten(),    \n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
        "    ax[0].plot(model.history.history['accuracy'])\n",
        "    ax[1].plot(model.history.history['loss'])\n",
        "    ax[2].plot(model.history.history['val_accuracy'])\n",
        "    ax[3].plot(model.history.history['val_loss'])\n",
        "    print('Validation accuracy: ', model.history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Basic Convolutional Model w/ 128 input neurons and 2 Dropout layers')\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('training accuracy')\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('training loss')\n",
        "ax[2].set_xlabel('epochs')\n",
        "ax[2].set_ylabel('testing accuracy')\n",
        "ax[3].set_xlabel('epochs')\n",
        "ax[3].set_ylabel('testing loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0NHmzBRgPtp"
      },
      "source": [
        "**Plot results for Model 4.2:**\n",
        "Shown in order: Training Accuracy, Training Loss, Testing Accuracy, Testing Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1s0JEdAzhnwm2JXAKybPpCLLaUFONF9C-'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1wwrvt7gPtq"
      },
      "source": [
        "As observed in the images above the models training loss improves after the 6th epoch and the testing loss begins to worsen. To address this we attempt to use early-stopping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4VQtKdRgPtq"
      },
      "source": [
        "## 5. Early Stopping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5ZY87lrgPtr"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):              \n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "        \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "    \n",
        "    #model.fit(x_train_more, y_train_more, epochs=6, validation_data=(x_test, y_test))       \n",
        "    model.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))        \n",
        "    \n",
        "    a.append(model.history.history['accuracy'])\n",
        "    b.append(model.history.history['loss'])\n",
        "    c.append(model.history.history['val_loss'])\n",
        "    d.append(model.history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzqcUzzMgPtu"
      },
      "source": [
        "**Plot results for Model 5:**\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1cWZlHJ-K1uI2x6p6yIEoghlei4Loyjtl'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1HK6OrLCA4yY2HycWwoaN6DQbuO344epE'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=13N0b7L9LeRmR9VDZzh-pxNoL6k1cuPHP'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1KQfSuKAuKh11ivuymhPS-8VDuIYpyM4W'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1inBgpGMnFiP3srb2KsHaFFZ3uZwn0NID'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3p2zkZ2gPtv"
      },
      "source": [
        "From the plots as seen above we can observe that this model performs better and addresses the overfitting that was occurring previously. However, the testing accuracy is still not that much better. We will now explore methods to improve the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrLGLwUlgPtv"
      },
      "source": [
        "## 6. Acquiring More Training Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id2NPxPdgPtv"
      },
      "source": [
        "A very common method to improve the accuracy of a model is by increasing the amount of training data. Although we could not acquire more data externally, we decided to include the development set to the training set to create a bigger training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBXZDk8wgPtw"
      },
      "outputs": [],
      "source": [
        "\"...\"\n",
        "x_train_more = asarray(photos_train.append(photos_dev))\n",
        "y_train_more = y_train.append(y_dev)\n",
        "\"...\"\n",
        "\n",
        "for _ in range(10): \n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "        \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "    \n",
        "    model.fit(x_train_more, y_train_more, epochs=6, validation_data=(x_test, y_test))       \n",
        "    #model.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))        \n",
        "    \n",
        "    a.append(model.history.history['accuracy'])\n",
        "    b.append(model.history.history['loss'])\n",
        "    c.append(model.history.history['val_loss'])\n",
        "    d.append(model.history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1478c5CgPty"
      },
      "source": [
        "actual output from network: [0.2710606  0.00456741 0.0137594  0.01716287 0.18178785 0.03163417\n",
        " 0.14130108 0.01684094 0.22918765 0.05834203 0.03085023 0.00350579]\n",
        "\n",
        "category (the largest output): 0\n",
        "\n",
        "[[806  83  48 186 386 150 389 254 285 203 109  58]\n",
        "\n",
        "[  0   0   0   0   0   0   0   0   0   0   0   0]  \n",
        "\n",
        "[  0   0   0   0   0   0   0   0   0   0   0   0] \n",
        "\n",
        "[  0   0   0   0   0   0   1   0   0   0   0   0]\n",
        "\n",
        "[ 16   4   2   2  16   3   9   2   1   4   0   0]\n",
        "\n",
        "[  0   0   0   0   0   0   0   0   0   0   0   0]\n",
        "\n",
        "[ 74  12   4  24  35  22  91  31  21  39   3   6]\n",
        "\n",
        "[  2   1   0   7   1   0   1   8   1   3   0   0]\n",
        "\n",
        "[ 58   5   5  11  24  16  33  15  74  15  14   6]\n",
        "\n",
        "[  3   2   0   9   5   4  10   3   2   9   5   1]\n",
        "\n",
        "[  0   0   0   0   0   0   0   0   0   0   1   0]\n",
        "\n",
        "[  0   0   0   0   0   0   0   0   0   0   0   0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuor_EqYgPt0"
      },
      "source": [
        "**Plot results for Model 6:**\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1kril7TF-9Fo7kW5FWUZzJjioGrlgMnig'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=17BwHCOFBRILPYnaREOpn8gzxM7ec-q8Z'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1BdA0RBvp0RP9Q1eRq-SDiN1fPbXbmk6-'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Bm2Rawu_VRAu4YkVaTpF77jsqdXJEm8Y'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTWLvciDgPt0"
      },
      "source": [
        "**This** model is slightly better than the model seen above by 1 or 2 percent and less randomized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-YEJs2rv0ZB"
      },
      "source": [
        "## 7.1 Data Augmentation with Initial Train Set, Batch Size of 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6Zptivs3Tzm"
      },
      "source": [
        "Data augmentation is another method of reducing overfitting. It essentially simulates a larger training set by applying image manipulations such as flips, shifts, grain, brightness changes, and colour variations to the dataset at random to create additional images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJzJ7LfBhIie"
      },
      "outputs": [],
      "source": [
        "# Adding data augmentation\n",
        "# Version 1: just rotation, shifts, and flips\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=45,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Data augmentation version 1\n",
        "fig, ax = plt.subplots(4, figsize=(12,24))\n",
        "for n in range(10):\n",
        "    print(f'run {n}')\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Flatten(),    \n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "\n",
        "    model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "              steps_per_epoch=len(x_train)/64, epochs=6, verbose=0,\n",
        "              validation_data=(x_test, y_test))\n",
        "    ax[0].plot(model.history.history['accuracy'])\n",
        "    ax[1].plot(model.history.history['val_accuracy'])\n",
        "    ax[2].plot(model.history.history['loss'])\n",
        "    ax[3].plot(model.history.history['val_loss'])\n",
        "    print('Validation accuracy: ', model.history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Convolutional Model w/ 4 hidden layers')\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('training accuracy')\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('testing accuracy')\n",
        "ax[2].set_xlabel('epochs')\n",
        "ax[2].set_ylabel('training loss')\n",
        "ax[3].set_xlabel('epochs')\n",
        "ax[3].set_ylabel('testing loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCBfqiLfhI7r"
      },
      "source": [
        "**Plot results for Model 7.1:**\n",
        "\n",
        "Training and Testing Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=11exgBLVG4nFT7xLbPqsJnQ8Bc4DS5Q4s'>\n",
        "\n",
        "Training and Testing Loss\n",
        "<img src='https://drive.google.com/uc?id=1IoJWp9qSCtZ-ke24Q_HKqBlj8VZYGwfN'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFEiRwOiCK6c"
      },
      "source": [
        "This model showed somewhat less of a disparity between the training and testing accuracy, indicating that the combination of early stopping and data augmentation helped to address the overfitting. However, there is still room for improvement in both reducing overfitting, as shown in the testing accuracy plot, and reducing error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCvMPgHowCgQ"
      },
      "source": [
        "## 7.2 Data Augmentation with Image Recolouring and Larger Train Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H69kpIgXC4ze"
      },
      "source": [
        "The next model maintains the early stopping at 6 epochs and data augmentation, but adds more features to the data augmentation and incorporates the dev data into the training set for a larger dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGUUucEpt0E9"
      },
      "outputs": [],
      "source": [
        "# Before trying a second round of data augmentation,\n",
        "# combine the dev and train datasets for more data \n",
        "\n",
        "# binary vectors representing all genres\n",
        "y_train = np.load(train_genres)\n",
        "y_dev = np.load(dev_genres)\n",
        "y_train_more = np.concatenate([y_dev,y_train])\n",
        "\n",
        "photos_train = []\n",
        "photos_train_more = []\n",
        "for file in dev_filenames:\n",
        "    photo = tf.keras.preprocessing.image.load_img(file, target_size=(128, 128))\n",
        "    #convert to numpy array\n",
        "    photo = tf.keras.preprocessing.image.img_to_array(photo)\n",
        "    #store\n",
        "    #photos_dev.append(photo/255)\n",
        "    photos_train_more.append(photo/255)\n",
        "x_dev = np.asarray(photos_dev)\n",
        "print('done dev')\n",
        "\n",
        "for file in train_filenames:\n",
        "    photo = tf.keras.preprocessing.image.load_img(file, target_size=(128, 128))\n",
        "    photo = tf.keras.preprocessing.image.img_to_array(photo)\n",
        "    photos_train.append(photo/255)\n",
        "    photos_train_more.append(photo/255)\n",
        "x_train_more = np.asarray(photos_train_more)\n",
        "print('done train')\n",
        "\n",
        "print(\"x_train shape:\",x_train.shape)\n",
        "print(\"x_train_more shape:\",x_train_more.shape)\n",
        "print(\"x_test shape:\",x_test.shape)\n",
        "\n",
        "print(\"y_train shape:\",y_train.shape)\n",
        "print(\"y_train_more shape:\",y_train_more.shape)\n",
        "print(\"y_test shape:\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXlvgmn6t3of"
      },
      "outputs": [],
      "source": [
        "# Version 2: addition of image colouring augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=45,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range=(0.75,1.25),\n",
        "        zca_whitening=False,\n",
        "        zca_epsilon=1e-06,\n",
        "        fill_mode='nearest')\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Data augmentation version 2\n",
        "fig, ax = plt.subplots(4, figsize=(12,24))\n",
        "for n in range(10):\n",
        "    print(f'run {n}')\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Flatten(),    \n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "\n",
        "    model.fit(datagen.flow(x_train_more, y_train_more, batch_size=64),\n",
        "              steps_per_epoch=len(x_train_more)/64, epochs=6, verbose=0,\n",
        "              validation_data=(x_test, y_test))\n",
        "    ax[0].plot(model.history.history['accuracy'])\n",
        "    ax[1].plot(model.history.history['val_accuracy'])\n",
        "    ax[2].plot(model.history.history['loss'])\n",
        "    ax[3].plot(model.history.history['val_loss'])\n",
        "    print('Validation accuracy: ', model.history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Data Augmentation')\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('training accuracy')\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('testing accuracy')\n",
        "ax[2].set_xlabel('epochs')\n",
        "ax[2].set_ylabel('training loss')\n",
        "ax[3].set_xlabel('epochs')\n",
        "ax[3].set_ylabel('testing loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyEMHCNS9myU"
      },
      "source": [
        "**Plot results for Model 7.2:**\n",
        "\n",
        "Training Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=12dzGcojFX2w_fhnOjTrx-jpve8lYF_uk'>\n",
        "\n",
        "Testing Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=13duiSgH8p_6dYsnQhwzwTW6mL3vJswyF'>\n",
        "\n",
        "Training Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1_04aub3xJbsxucCdlWKMjXnl7q388_Gd'>\n",
        "\n",
        "Testing Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1iMITrHi4r2XcsK2Y0zChN_RmPvvzhYTM'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmD4lQreGWIu"
      },
      "source": [
        "This model showed significant improvements in the testing loss, where the model in **8.1** ranged from 3-10, in this model loss is under 2.25. The next model will apply one final modification to this one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ABOAnvwrgE"
      },
      "source": [
        "## 7.3 Data Augmentation with Batch Size of 32 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJyxj2boGwvQ"
      },
      "source": [
        "This model is almost identical to the previous model, using the larger training set and data augmentation. However, the batch size of the `datagen.flow` step has been reduced from 64 to 32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-moa2MSuNhW"
      },
      "outputs": [],
      "source": [
        "# Data augmentation version 3\n",
        "fig, ax = plt.subplots(4, figsize=(12,24))\n",
        "for n in range(10):\n",
        "    print(f'run {n}')\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Flatten(),    \n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "\n",
        "    model.fit(datagen.flow(x_train_more, y_train_more, batch_size=32),\n",
        "              steps_per_epoch=len(x_train_more)/32, epochs=6, verbose=0,\n",
        "              validation_data=(x_test, y_test))\n",
        "    ax[0].plot(model.history.history['accuracy'])\n",
        "    ax[1].plot(model.history.history['val_accuracy'])\n",
        "    ax[2].plot(model.history.history['loss'])\n",
        "    ax[3].plot(model.history.history['val_loss'])\n",
        "    print('Validation accuracy: ', model.history.history['val_accuracy'])\n",
        "\n",
        "ax[0].set_xlabel('epochs')\n",
        "ax[0].set_ylabel('training accuracy')\n",
        "ax[1].set_xlabel('epochs')\n",
        "ax[1].set_ylabel('testing accuracy')\n",
        "ax[2].set_xlabel('epochs')\n",
        "ax[2].set_ylabel('training loss')\n",
        "ax[3].set_xlabel('epochs')\n",
        "ax[3].set_ylabel('testing loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVltMc5P_Gyc"
      },
      "source": [
        "**Plot results for Model 7.3:**\n",
        "\n",
        "Training Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1IT0xIzb-mzMGVI05dy4U5gunzrLWr9k-'>\n",
        "\n",
        "Testing Accuracy\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1kKmJxAjgD6W888gx-J4LzKQvePWh4zrx'>\n",
        "\n",
        "Training Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Kyzf0mHk2MWk3FfmecFtbMsJF4p8x3ei'>\n",
        "\n",
        "Testing Loss\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1pr3Q9V5wovgzzHSt-xZ9PNlmgWwSFMWQ'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6dhhZRYHbbf"
      },
      "source": [
        "This final model did not show a very noticeable improvement over the previous model. However, the overfitting has been reduced, and it may be possible to see an increase in accuracy with more epochs. After closer inspection of the labelling distribution in the training dataset, we realized that there is a large imbalance in regards to how the labels are distributed in the training set which is likely causing the algorithm to be biased towards the majority values present.\n",
        "\n",
        "Looking at the distributions of each genre within the dataset, we observed that there is an uneven distribution of each genre, which likely effects the accuracy of the classification. To combat this, we tried implementing Class Weights.\n",
        "<img src='https://drive.google.com/uc?id=1ikhtd11cfP2N5Sdl5j_hTLwoxN4mXtXm'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WlImjXrgPt0"
      },
      "source": [
        "## 8. Adding Class Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhwEtXEtgPt1"
      },
      "source": [
        "To account for this imbalance in labels we decided to add class weights which will influence the classification of the classes during the training phase. The main purpose is to penalize the misclassification made by the minority class by setting a higher class weight and at the same time reducing weight for the majority class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_4_K5XSgPt1"
      },
      "outputs": [],
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train_more), y_train_more)\n",
        "weight = {i : class_weights[i] for i in range(12)}\n",
        "\n",
        "weight_decay = 1e-4\n",
        "for _ in range(10):              \n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "      \n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy']  # in addition to the loss, also compute the categorization accuracy\n",
        "                 )\n",
        "    \n",
        "    model.fit(x_train_more, y_train_more, epochs=6, validation_data=(x_test, y_test), class_weight = weight)       \n",
        "    #model.fit(x_train, y_train, epochs=6, validation_data=(x_dev, y_dev))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDw5uvyNgPt3"
      },
      "source": [
        "actual output from network: [0.08180414 0.03029461 0.0525596  0.03892834 0.17196111 0.04264539\n",
        " 0.08377606 0.042708   0.12648761 0.06940803 0.20566058 0.05376663]\n",
        "category (the largest output): 10\n",
        "[[ 19   0   0   0   8   0  10   3   4   0   2   0]\n",
        " [ 80   9   4  18  28  15  25  19  20  13   8   5]\n",
        " [217  29   8  51  99  46 108  73  45  60  16   8]\n",
        " [ 43   8   4  20  16  18  24  22   9  17   3   5]\n",
        " [ 99   9   3  18  64  15  42  22  25  10  11   8]\n",
        " [ 21   4   2   3  11   4  17   9   6   6   1   0]\n",
        " [ 25   3   2   9  18   7  24   7   7   9   5   3]\n",
        " [ 37  11   5   8  22  14  31  32  14  16   5   6]\n",
        " [176  13  14  37  82  31 107  41 158  45  24  11]\n",
        " [ 94  11   8  43  59  25  84  44  49  51  10  16]\n",
        " [118   6   6  24  45  14  41  27  41  34  44   7]\n",
        " [ 30   4   3   8  15   6  21  14   6  12   3   2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSTq9ugdgPt4"
      },
      "source": [
        "**Plot results for Model 8:**\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=10Y7onkbIWgwS3FVosfz0_kqs5ru8--tv'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1o-S56M0cHmNFmZIA4Gtunz85OcCATcqW'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1igIiWlrd6YJ3TT9YtSZeMGL8APt2jw1B'>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=12E14ja-4reKyqNrcVjHGqaNMKaS7xidu'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDiIQZD3gPt5"
      },
      "source": [
        "With this we see that the model does not perform that well however we believe it is a better representative of the machine learning model that we are trying to achieve. We will discuss this in the conclusion below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb10nRRLgPt5"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7l-DHdRgPt6"
      },
      "source": [
        "In conclusion, we have a few models that we think were successful and reported worthy results. First, better performing models were the ones that had early stopping and drop out layers to consider overfitting. The model with more data to work with from the dev showed better performance. The models which used data augmentation also showed less overfitting, because they simulated more data by creating slight variations in the images. Our last model that we suspect is most accurate is the one that considers the class weights. Although it did worse than the other models we suspect that it is more accurate because it takes into consideration the disproportionate number of data points from class to class. We should have started developping our model with class weights first to achieve better and more accurate models. The reason that our other models were attaining better \"validation accuracy\" was because those models were biased towards the first label, which make. The model would predict the test label for most cover arts to be the first label, which was oftentimes the case anyways since the test/training data were equally disproportionate of the classes. This explains why we were able to get 25% accuracies but if we considered the class-weights it would have likely been outputting lower accuracies within the 10-20% range.\n",
        "\n",
        "From the models that we have developed over the course of this project, we may suspect that the issue stems from the nature of the object that we are trying to classify and the given labels.  When we attempt to classify the genre of an image, this can be more complex than just trying to classify its shape. In other datasets like the MNIST hand-written digits or the CIFAR-10 images that we dealt with in class, they were able to take out structures or distinguishable patterns for object detection which can be consistent across a particular label. However, in our case, it can be difficult to identify an agreeable pattern pertaining to each album cover. Moreover, it is not simply the classification of what is inside the image, but the capability to connect the objects within the image and determine the style or aesthetic that is indicative of the genre. \n",
        "Additionally, other well-performing models have significantly much more data to build their model on, i.e the CIFAR-10 has 60,000 and other more complex machine-learning models have hundreds of thousands of images for their model. Our dataset had a maximum number of 14,581 images to train our network on. We also would like to acknowledge that our results may have also underperformed as a consequence of how our labels were grouped. Many of the genres are similar to one another or can be considered sub-genres of the other. For instance, our first label is Rock and our ninth label is Metal, where metal is oftentimes considered a sub-genre of the main genre Rock. A way to address this in the future is multi-labelling the cover art, specifically by their sub-genres. The sub-genres can be easier to classify than the main genre with more specific features pertaining to one as opposed to a range seen in the main genre.\n",
        "\n",
        "### Future approaches\n",
        "\n",
        "Given the time and the computer resources, we could test on other CNN models such as AlexNet, Resnet34, Resnet 18 and Resnet152. We would also like to explore the option of testing on pre-trained versions of the model architectures mentioned above. Some have attempted album cover art classification with the approaches mentioned above and yet have also acknowledged that they were unsuccessful due to the data that the model had pre-trained on, one of them being CIFAR-10, which would justify the poor performance on the album cover/ genre dataset where the classification is far less objective [1]. Others have also reported success in pre-trained models, specifically the VGG16 which was trained on the imagenet dataset [2]. We would like to explore the latter approach and see how our data would perform with a model like so. Additionally, we would like to see how well our current model would perform in multi-labelling album cover art and see how that would perform on other more complex models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[1] Nathan Lee and Robert Baraldi. CSE 546 final paper predicting musical genre from album cover art.\n",
        "\n",
        "[2] Jonathan Li, Tongxin Cai and Di Sun,.CSE 230 Stanford University Genre Classification via Album Cover.\n",
        "\n",
        "[3] Akshi Kumar, Arjun Rajpal, and Dushyant Rathore. Genre classification using feature extraction and deep learning techniques. pages 175–180, 2018.\n",
        "\n",
        "[4] Christian Koenig. Classifying album genres by artwork. 2017. \n",
        "\n",
        "*Dataset:*\n",
        "\n",
        "Oramas S., Nieto O., Barbieri F., & Serra X. (2017). Multi-label Music Genre Classification from audio, text and images using Deep Features. In Proceedings of the 18th International Society for Music Information Retrieval Conference (ISMIR 2017). https://arxiv.org/abs/1707.04916\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pLMJxefFgPtd",
        "p7l-DHdRgPt6"
      ],
      "name": "Album Cover Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
